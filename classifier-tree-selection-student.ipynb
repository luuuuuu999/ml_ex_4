{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"487d6a0e","cell_type":"markdown","source":"# **Esercitazione 4 - Classificatori: KNN e Decision Trees**\n\nIn questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n\n* **K-Nearest Neighbors (KNN):** Un algoritmo di classificazione basato sulla similarità che assegna una classe a un'osservazione in base alle classi dei suoi \"K\" vicini più prossimi.\n\n* **Decision Trees:** Un modello di classificazione che utilizza una struttura ad albero per prendere decisioni basate su regole derivate dalle caratteristiche dei dati.","metadata":{}},{"id":"1c0e7c81","cell_type":"markdown","source":"### **Dataset Breast Cancer**\n\nIl dataset di riferimento sarà `breast_cancer`, un noto dataset di classificazione che contiene informazioni su tumori al seno. Le osservazioni includono diverse caratteristiche misurate sui tumori, come dimensioni, forma e altre metriche, con l'obiettivo di classificare i tumori in due categorie: **benigni** e **maligni**.\n\nPer questa esercitazione, utilizzeremo l'intero dataset, mantenendo le classi originali. Il dataset è composto da 569 campioni e 30 caratteristiche, e utilizzeremo questo set per costruire i modelli di classificazione.\n\nIl codice seguente esegue l'importazione delle librerie necessarie, il caricamento del dataset `breast_cancer` e la preparazione dei dati. In particolare, gestiremo i dati e le etichette in modo da facilitare l'uso dei classificatori K-Nearest Neighbors (KNN) e Decision Trees.\n\nDal caricamente del dataset estrarremo anche i nomi delle feature e della variabile target perchè ci servirà più avanti.","metadata":{}},{"id":"08d3ff15","cell_type":"code","source":"# Importazione delle librerie necessarie\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{},"outputs":[],"execution_count":1},{"id":"8f8b8f61","cell_type":"code","source":"# Caricamento del dataset Iris\ndataset = load_breast_cancer()\nX = dataset.data\ny = dataset.target\n\n# Estraggo nomi delle feature e dei target\nfeature_names = dataset.feature_names\ntarget_names = dataset.target_names","metadata":{},"outputs":[],"execution_count":null},{"id":"724f22cb","cell_type":"markdown","source":"### **Divisione e standardizzazione del dataset** \n\nDividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`.","metadata":{}},{"id":"84b8b157","cell_type":"code","source":"# Usare le seguenti proporzioni per il train, validation e test\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2\n\nnum_train = int(train_fraction * X.shape[0])\nnum_validation = int(validation_fraction*X.shape[0])\n\nX_train = X[:num_train]\ny_train = y[:num_train]\nX_validation = X[num_train:num_train+num_validation]\ny_validation = y[num_train:num_train+num_validation]\nX_test = X[num_train+num_validation:]\ny_test = y[num_train+num_validation:]\n\nprint(\"Train shape:\", X_train.shape)\nprint(\"Validation shape:\", X_validation.shape)\nprint(\"Test shape:\", X_test.shape)\n\n#Standardizzazione\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_validation = scaler.transform(X_validation)\nX_test = scaler.transform(X_test)","metadata":{},"outputs":[],"execution_count":null},{"id":"5102c517","cell_type":"markdown","source":"## **Esercizio 1: Implementare K-NN**\n\nPer implementare il classificatore K-Nearest Neighbors utilizzeremo la classe `sklearn.neighbors.KNeighborsClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n\nDi seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n\n* **`n_neighbors`**: Numero di vicini da considerare. Valori più elevati implicano una maggiore generalizzazione.\n* **`weights`**: Specifica come pesare i vicini; può essere `uniform` (tutti i vicini hanno lo stesso peso) o `distance` (i vicini più prossimi hanno un peso maggiore).\n* **`metric`**: Tipo di distanza da utilizzare per calcolare la distanza tra i punti (ad esempio, `euclidean`, `manhattan`, ecc.).\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n# Importo KNeighborsClassifier da scikit-learn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 1. Instanzio il modello KNN\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n# 3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n\n```","metadata":{}},{"id":"90f5938f","cell_type":"markdown","source":"### **Guida per la risoluzione del K-Nearest Neighbors (KNN)**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell'esercizio utilizzando il classificatore K-Nearest Neighbors.\n\n1. **Creazione del modello:** Creare un'istanza della classe `KNeighborsClassifier`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n\n    - `n_neighbors` = 5\n\n    - `weights` = `'uniform'` (o `'distance'` se vuoi dare un peso maggiore ai vicini più prossimi)\n\n    - `metric` = `'euclidean'` (puoi cambiare con `'manhattan'` se preferisci un'altra metrica di distanza)\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di training. Assicurati che i dati siano adeguatamente preprocessati e, se necessario, normalizzati o standardizzati.\n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e sul test set utilizzando il metodo `.predict()` del modello.\n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l'accuracy del modello. Possono essere utilizzate anche altre metriche, come la precisione, il richiamo e il punteggio F1, per ottenere una valutazione più completa. Dobbiamo valutare il modello sia sul validation set che sul test set e infine stampare il valore di accuracy su entrambi i set.\n\n5. **Calcolare la matrice di confusione:** Calcolare la matrice di confusione.","metadata":{}},{"id":"6803b23b","cell_type":"code","source":"# Step 1: Creazione del modello KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')","metadata":{},"outputs":[],"execution_count":null},{"id":"66ea01d4","cell_type":"code","source":"# Step 2: Addestramento del modello KNN\n\nmodel.fit(X_train, y_train)","metadata":{},"outputs":[],"execution_count":null},{"id":"d396900e","cell_type":"code","source":"# Step 3: Calcolo delle predizioni\n\ntest_predictions = model.predict(X_test)\nval_predictions = model.predict(X_validation)","metadata":{},"outputs":[],"execution_count":null},{"id":"d40ef061","cell_type":"code","source":"# Step 4: Valutazione del modello KNN\nfrom sklearn.metrics import accuracy_score\ntest_acc = accuracy_score(y_test, test_predictions)\nval_acc = accuracy_sore(y_validation, val_predictions)","metadata":{},"outputs":[],"execution_count":null},{"id":"3142e27e","cell_type":"markdown","source":"#### Funzione alternativa per il calcolo dell' accuracy\n\nFinora abbiamo calcolato manualmente il valore dell' accuracy. Ovvero abbiamo confrontato il vettore delle predizioni con il vettore dei target e successivamente contato quanti campioni combaciano, in modo da avere il numero di predizioni effettuate correttamente. Possiamo effettuare questo calcolo anche utilizzando una funzione di `sklearn`.\n\nLa funzione `accuracy_score` infatti ci calcola in automatico il valore dell' accuracy. La sintassi per utilizarla è la seguente\n\n```python\n# Importo accuracy_score da scikit-learn\nfrom sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_true, y_pred)\n\n```","metadata":{}},{"id":"354dc544","cell_type":"code","source":"# Step 4.1: Calcolare l' accuracy con accuracy_score\n\n# fatto sopra","metadata":{},"outputs":[],"execution_count":null},{"id":"9cc51143","cell_type":"code","source":"# Step 5: Calcolare la matrice di confusione\nfrom sklearn.metrics import confusion_matrix\ntest_cm = confusion_matrix(y_test, y_pred)\nval_cm = confusion_matrix(y_validation, val_predictions)\nprint(test_cm)\nprint(val_cm)\n\n","metadata":{},"outputs":[],"execution_count":null},{"id":"c83cdbd2","cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_decision_boundary(knn_model, X_train, y_train):\n\n    h = 0.1  \n    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    \n    Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    unique_classes = np.unique(y_train)\n    \n    plt.figure(figsize=(10, 8))\n    plt.contourf(xx, yy, Z, alpha=0.5, cmap=plt.cm.RdYlBu)  \n    \n    scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o', \n                          label='Training set', cmap=plt.cm.RdYlBu, s=20)  \n\n    plt.title(f'Confini Decisionali di K-Nearest Neighbors')\n    plt.legend(scatter.legend_elements()[0], unique_classes, title='Classi')\n    plt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"c4ef4dfc","cell_type":"markdown","source":"### Visualizzazione K-NN\n\nPer visualizzare il margine di classificazione del nostro K-NN dobbiamo utilizzare soltanto 2 features. Poichè nel dataset ne sono presenti 30 abbiamo due soluzioni:\n\n1. **Utilizzare le prime due features del dataset:** soluzione più rapida ma che non ci garantisce un risultato ottimale, in quanto l' ordine delle features non ha alcuna rilevanza circa la loro importanza. **ATTENZIONE:** poichè stiamo utilizzando solo 2 features, dobbiamo riaddestrare il K-NN sul dataset ridotto.\n\n2. **Applicare PCA con 2 componenti:** applichiamo la PCA con due componenti che utilizziamo successivamente per trasformare i nostri dati.\n\nDi seguito applicheremo entrambe le soluzioni e alla fine confronteremo i risultati.","metadata":{}},{"id":"8829d633","cell_type":"code","source":"# Visualizzazione con due feature\n\nX_train2 = X_train[:, :2]\nX_validation2= X_validation[:, :2]\nX_test2 = X_test[:, :2]\n\n# Standardizziamo il dataset ridotto\nscaler = StandardScaler()\nX_train2 = scaler.fit_transform(X_train2)\nX_validation2= scaler.transform(X_validation2)\nX_test2 = scaler.transform(X_test2)\n\n\n# Creiamo e addestriamo il K-NN sul dataset ridotto e scalato\nmodel2 = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\nmodel2.fit(X_train2, y_train)\n\ntest_predictions2 = model2.predict(X_test2)\nval_predictions2 = model2.predict(X_validation2)\n# Utilizziamo la funzione plot_decision_boundary per visualizzare il confine decisionale\n\nplot_decision_boundary(model2, X_train2, y_train)","metadata":{},"outputs":[],"execution_count":null},{"id":"a641f56a","cell_type":"code","source":"# Visualizzazione con PCA\nfrom sklearn.decomposition import PCA\n\n# Applichiamo PCA per ridurre il dataset a 2 dimensioni. ATTENZIONE: per applicare PCA dobbiamo prima standardizzare.\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_validation = scaler.transform(X_validation)\n\n# Riduzione delle dimensioni con PCA\npca = PCA(n_components=2) \nX_train = pca.fit_transform(X_train) \nX_validation = pca.transform(X_validation)\n\nprint(X_train.shape)\nprint(X_validation.shape)\n\n\n# Classificatore KNN su dati PCA\nmodel2 = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\nmodel2.fit(X_train, y_train)\ny_predictions_validation = model2.predict(X_validation)\ncm = confusion_matrix(y_validation, y_predictions_validation)\n\n# Plot\n\nplot_decision_boundary(model2, X_train, y_train)","metadata":{},"outputs":[],"execution_count":null},{"id":"f4c49b73","cell_type":"markdown","source":"## **Esercizio 2: valutare le prestazioni di K-NN al variare di k e metrica**\n\nValutiamo come variano le prestazioni del classificatore al variare di:\n\n* **k:** usiamo diversi valori di k.\n\n* **metrica**: usiamo diverse distanze, non solo quella euclidea.\n\n\n### **Guida:**\n\n1. **Testiamo il classificatore al variare del parametro:** che sia il k o la distanza, dobbiamo istanziare, allenare e valutare il classificatore per ogni valore che ci interessa. Alla fine di ogni test che effettuiamo, saliamo il valore di accuracy ottenuto in una lista.\n\n2. **Valutazione grafica:** utilizziamo la funzione di plot per valutare quale valore del parametro di interesse ci fa ottenere la performance migliore.\n\n","metadata":{}},{"id":"c5068b74","cell_type":"code","source":"# Funzione per la valutazione grafica\n\ndef plot_accuracy_k(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    \n    plt.xlabel('Numero di k')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Valore di k')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"57f7baf2","cell_type":"code","source":"# Valutiamo le performance al variare di k\n\nk_values = range(1, 15) \ntrain_scores = []\ntest_scores = []\n\n# Istanziamo, alleniamo e valutiamo un K-NN per ogni valore di k \n\n    model = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='euclidean')\n    model.fit(X_train, y_train)\n\n    train_scores.append(accuracy_score(y_train, model.predict(X_train)))\n    test_scores.append( accuracy_score(y_validation, model.predict(X_validation)))\n# Visualizziamo le performance al variare di k\n# N.B. la funzione plot_accuracy_k ha bisogno dei parametri k_values, train_scores, test_scores.\nplot_accuracy_k(k_values, train_scores, test_scores)","metadata":{},"outputs":[],"execution_count":null},{"id":"2a66262d","cell_type":"code","source":"# Funzione per plottare l' accuracy al variare delle metriche\n\ndef plot_accuracy_metric(metrics, train_scores, test_scores):\n    bar_width = 0.35\n    x = np.arange(len(metrics))  \n\n    plt.figure(figsize=(12, 6))\n\n    color_train = plt.cm.RdYlBu(0.9)  \n    color_test = plt.cm.RdYlBu(0.4)   \n\n    bars_train = plt.bar(x - bar_width/2, train_scores.values(), width=bar_width, label='Training', color=color_train)\n    bars_test = plt.bar(x + bar_width/2, test_scores.values(), width=bar_width, label='Testing', color=color_test)\n\n    plt.xticks(ticks=x, labels=metrics)  \n    plt.xlabel('Metriche')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Metriche')\n    plt.legend(loc='lower right')\n    plt.grid(axis='y')\n    \n    for bar in bars_train:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    for bar in bars_test:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"7021496a","cell_type":"code","source":"# Valutiamo le performance al variare della metrica\n# in questo caso le performance devono essere salvate in un dizionario. Ogni chiave sarà il nome della metrica usata, il valore corrispondente invece sarà l' accuracy ottenuta.\n\nmetrics = ['euclidean', 'manhattan', 'minkowski', 'cosine']\ntest_scores = {}\ntrain_scores = {}\n\n# Istanziamo, alleniamo e valutiamo un K-NN per ogni metrica. Utilizziamo k=5.\n    model = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric=metric)\n    model.fit(X_train, y_train)\n\n    # Salviamo i risultati nel dizionario\n    train_scores[metric] = accuracy_score(y_train, model.predict(X_train))\n    test_scores[metric] = accuracy_score(y_validation, model.predict(X_validation))\n\n\n# Visualizziamo le performance al variare della metrica\n# N.B. la funzione plot_accuracy_metric ha bisogno dei parametri metrics, train_scores, test_scores.\nplot_accuracy_metric(metrics, train_scores, test_scores)","metadata":{},"outputs":[],"execution_count":null},{"id":"432f7f94","cell_type":"markdown","source":"## **Esercizio 2: Implementare Decision Trees**\n\nPer implementare il classificatore Decision Tree, utilizzeremo la classe `sklearn.tree.DecisionTreeClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n\nDi seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n\n* **`criterion`**: Funzione da utilizzare per misurare la qualità di uno split. \n\n* **`max_depth`**: Profondità massima dell'albero. Limitare la profondità aiuta a prevenire l'overfitting.\n\n* **`min_samples_split`**: Numero minimo di campioni richiesti per dividere un nodo. Valori più alti rendono l'albero più conservativo.\n\n* **`min_samples_leaf`**: Numero minimo di campioni che devono essere presenti in un nodo foglia. Prevenire nodi foglia con pochi campioni può migliorare la generalizzazione.\n\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n# Importo DecisionTreeClassifier da scikit-learn\nfrom sklearn.tree import DecisionTreeClassifier\n\n# 1. Instanzio il modello Decision Tree\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10)\n\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n# 3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n","metadata":{}},{"id":"afcba9f7","cell_type":"markdown","source":"## **Esercizio 3: Istanziare allenare e valutare un modello DecisionTree**\n\nIn linea con quanto visto finora, istanziamo, alleniamo e valutiamo un modello di DecisionTree. Utilizziamo:\n\n* `criterion`=`'entropy'`\n\n* `random_state` = 42 \n\nIl valore di `random_state` non ha un significato particolare, ma ci permette di rendere l' esperimento deterministico. \n\nI passaggi per questo esercizio sono uguali a quanto visto in precedenza per K-NN.","metadata":{}},{"id":"29449cdc","cell_type":"code","source":"# Importiamo DecisionTree \nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{},"outputs":[],"execution_count":null},{"id":"54090eec","cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Step 1 - Creiamo un albero decisionale\nmodel3 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n\n# Step 2 - Alleniamo il modello\nmodel3.fit(X_train_2f, y_train)\n\n# Step 3 - Calcoliamo le predizioni\ny_predictions3 = model_dt.predict(X_test_2f)\n\n# Step 4 - Valutiamo il modello, calcoliamo accuracy e confusion matrix\naccuracy3 = accuracy_score(y_test, y_predictions3)\nprint(accuracy3)\n\ncm3 = confusion_matrix(y_test, y_predictions3)","metadata":{},"outputs":[],"execution_count":null},{"id":"e7a16dfe","cell_type":"code","source":"# Visualizzazione dell'albero creato\n# dovete sostituire alla funzione plot_tree il primo parametro. Nello specifico dovete sostituirlo con il nome che avete dato al vostro DecisionTree.\n\nplt.figure(figsize=(20, 10))\nplot_tree(dt_classifier, feature_names=feature_names, class_names=target_names, \n          filled=True, rounded=True, fontsize=12)\nplt.title('Decision Tree')\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"4ff6d7f0","cell_type":"markdown","source":"## **Esercizio 4: Valutiamo le performance di un DecisionTree al variare di alcuni parametri**\n\nCome abbiamo fatto per K-NN, vogliamo valutare come variano le performance di un Decision Tree al variare di alcuni parametri. Nello specifico vogliamo valutare il modello al variare di:\n\n* **`max_depth`**: Profondità massima dell'albero. \n","metadata":{}},{"id":"689aea93","cell_type":"code","source":"# Funzione per plottare l' accuracy al variare della max_depth del modello\n\ndef plot_accuracy_depth(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    \n    plt.xlabel('Profondità massima dell\\'albero')\n    plt.ylabel('Accuratezza')\n    plt.title('Decision Tree: Accuratezza vs. Depth')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"7f9d03e7","cell_type":"code","source":"# Confrontiamo alberi con diverse profondità massime\n\nmax_depths = [2, 3, 4, 5]\ntrain_accuracy = []\ntest_accuracy = []\n\n# Istanziamo, alleniamo e valutiamo un DecisionTree per ogni valore di max_depth\n\nfor depth in max_depths:\n    model4 = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)\n    \n    # Addestriamo il modello\n    model4.fit(X_train, y_train)\n    \n    # Calcoliamo le predizioni\n    train_predictions4 = model.predict(X_train)\n    test_predictions4 = model.predict(X_test)\n    train_accuracy.append(accuracy_score(y_train, train_predictions))\n    test_accuracy.append(accuracy_score(y_test, test_predictions))\n\n# Visualizziamo l'effetto della profondità sull'accuratezza\nplot_accuracy_depth(max_depths, train_accuracy, test_accuracy)","metadata":{},"outputs":[],"execution_count":null},{"id":"58b02676","cell_type":"markdown","source":"## **Esercizio 5: Ottimizzazione Decision Tree con GridSearch e Cross Validation**\n\nPossiamo ottimizzare le performance di un Decision Tree specificando ulteriori parametri. Lo scopo di questo esercizio è trovare la miglior combinazione di parametri che massimizza l' accuracy del nostro modello. Per trovare questa configurazione utilizzeremo la funzione `GridSearchCV` che effettua Grid Search e Cross Validation contemporaneamente.\n\nInnanzitutto proviamo a istanziare un Decision Tree specificando più parametri. Nello specifico impostiamo:\n\n* `max_depth` = `3`\n\n* `min_samples_split` = `5`\n\n* `min_samples_leaf` = `2`\n\nVediamo se l' aggiunta di questi parametri incrementa le performance ottenute precedentemente.\n\nOvviamente i parametri impostati precedentemente devono essere mantenuti.","metadata":{}},{"id":"12b14dc2","cell_type":"code","source":"# Albero ottimizzato con parametri più controllati\n\nmodel5 = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=5, min_samples_leaf=2, random_state=42\n)\n# Alleniamo l' albero\n\nmodel5.fit(X_train_2f, y_train).\n\n\n# Effettuare le predizioni del nuovo albero allenato\ntest_predictions5 = model5.predict(X_test)\nval_predictions5= model5.predict(X_validation)\n\n\n# Rappresentiamo il nuovo albero\n# Dovete sostituire il primo parametro della funzione plot_tree con il nome del vostro albero.\n\nplt.figure(figsize=(15, 8))\nplot_tree(model5, feature_names=feature_names, class_names=target_names, \n          filled=True, rounded=True, fontsize=10)\nplt.title('Albero Decisionale')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"65dda958","cell_type":"markdown","source":"#### **Importanza delle features**\n\nPossiamo estrarre dal nostro modello Decision Tree l' importanza delle singole feature, cioè quanto una feature aiuda a ridurre il criterio scelto, l' entropia nel nostro caso. \n\nQuesta informazione è contenuta in `.feature_importances_`. \n\nUna volta estratti questi valori, ordiniamoli in ordine decrescente e utilizziamo la funzione `plot_top_feature_importance` definita nella cella seguente per rappresentarne il grafico. La funzione richiede due parametri:\n\n* **Vettore importanze:** il vettore contenente l' importanza delle features ottenuto dall' estrazione.\n\n* **Nomi delle features:** i nomi delle feature che abbiamo estratto all' inizio dell' esercitazione quando abbiamo importato il dataset.","metadata":{}},{"id":"e43f274b","cell_type":"code","source":"def plot_top_feature_importance(importances, feature_names):\n    # Ordina le importanze e ottieni i primi `top_n` indici\n    top_n=10\n    indices = np.argsort(importances)[::-1][:top_n]\n\n    plt.figure(figsize=(10, 6))\n    plt.title('Importanza delle Feature')\n    \n    # Plotta solo le prime `top_n` barre\n    plt.bar(range(top_n), importances[indices], align='center', color='skyblue')\n    \n    plt.xticks(range(top_n), [feature_names[i] for i in indices], rotation=45)\n    plt.xlabel('Feature')\n    plt.ylabel('Importanza')\n    plt.tight_layout()  # Aggiunge spazio tra i lati del grafico\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"30b07808","cell_type":"code","source":"# Estrai l' importanza delle features da .feature_importances_\nimportances = model5.feature_importances_\n\n\n# Riordina in ordine decrescente\n \n#le riordina dentro la funzione\n\n# Rappresentiamo il grafico\nplot_top_feature_importance(importances, feature_names)","metadata":{},"outputs":[],"execution_count":null},{"id":"b437e3d1","cell_type":"markdown","source":"### **Grid search**\n\nPoichè i parametri impostabili in un modello sono numerosi testare le singole configurazioni è dispendioso. Tuttavia la ricerca dei parametri ottimali è l' unico modo che abbiamo per assicurarci di estrarre la miglior performance dal nostro modello. In questi casi ci sono diverse strateggie per cercare la configurazione migliore. Una di questa è la **Grid search** (letteralmente **ricerca a griglia**) che consiste nel testare tutte le possibili configurazioni e selezionare la migliore. Chiaramente testare tutte le configurazioni rende il grid search un algoritmo molto dispendioso dal punto di vista computazionale.\n\nPossiamo implementare un algoritmo di grid search utilizzando la classe `GridSearchCV` di `sklearn` che effettua contemporaneamente ricerca a griglia e cross-validation. \n\n#### Guida per Grid Search:\n\nI seguenti passaggi devono guidarvi all' utilizzo di `GridSearchCV` per trovare la miglior configurazione per un modello di DecisionTree per il nostro dataset.\n\n1. **Istanziamo un' oggetto `GridSearchCV`:** per creare l' oggetto `GridSearchCV` dobbiamo specificare i seguenti parametri\n\n    * Modello che vogliamo usare\n\n    * Dizionario contenente come chiavi i parametri che vogliamo testare, e come value i valori che vogliamo impiegare\n\n    * `cv` cioè il nomero di fold che vogliamo utilizzare per la cross-validaton\n\n    * `scoring` ovvero la metrica da utilizzare per valutare, ad esempio `accuracy`\n\n2. **Eseguire Grid Search:** utilizziamo il metodo `.fit()` dell' oggetto `GridSearchCV` definito al punto 1 per eseguire l' algoritmo\n\n3. **Stampare configurazione migliore:** dopo aver eseguito il `.fit()`, l' oggetto `GridSearchCV` ci permette di accedere ad alcuni attributi:\n\n    * `.best_params_`: un dizionario che rappresenta la miglior configurazione.\n\n    * `.best_scores_`: il valore migliore ottenuto come accuracy.\n\n    * `.best_estimator_`: il modello allenato con la configurazione migliore. ","metadata":{}},{"id":"851f3973","cell_type":"code","source":"# Step 1 - Istanziare l' oggetto GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Definizione del grid di parametri\nparam_grid = {\n    'max_depth': [3, 4, 5, 6, 7, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['entropy']\n}\n\ngrid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')","metadata":{},"outputs":[],"execution_count":null},{"id":"91b20d57","cell_type":"code","source":"# Step 2 - Eseguire Grid Search\n\ngrid_search.fit(X_train, y_train)","metadata":{},"outputs":[],"execution_count":null},{"id":"bd109bd5","cell_type":"code","source":"# Step 3 - Stampare i risultati\n# Stampare la migliore configurazione e la migliore accuracy\n\nprint(\"Migliori configurazion:\", grid_search.best_params_)\nprint(\"Migliore accuracy:\", grid_search.best_score_)\nbest_model = grid_search.best_estimator_ \nbest_pred = best_model.predict(X_test_2f) \nfrom sklearn.metrics import accuracy_score\nbest_accuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy modello migliore su test set: {accuracy:.4f}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"18b8e613","cell_type":"markdown","source":"# **Esercizio 6: Model Selection classificatori**\n\nAvendo affrontato tutti i classificatori visti in questo corso, possiamo adesso procedere alla fase di **model selection**. Vogliamo trovare quale classificatore la relativa configurazione che meglio performano su uno specifico dataset. \n\n### **Dataset**\n\nPer questo esercizio utilizzeremo il dataset `Vehicle Silhouette` che trovato al seguente [link](https://archive.ics.uci.edu/dataset/149/statlog+vehicle+silhouettes). Il dataset contiene 846 campioni su 18 features, e contiene informazioni circa le dimensioni di alcuni veicoli. L' obiettivo è classificare ogni campione in 4 possibili classi. ","metadata":{}},{"id":"bab558cf","cell_type":"code","source":"!pip install ucimlrepo","metadata":{},"outputs":[],"execution_count":null},{"id":"8ffb9b39","cell_type":"code","source":"from ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \nstatlog_vehicle_silhouettes = fetch_ucirepo(id=149) \n  \n# data (as pandas dataframes) \nX = statlog_vehicle_silhouettes.data.features \ny = statlog_vehicle_silhouettes.data.targets ","metadata":{},"outputs":[],"execution_count":3},{"id":"10713cae","cell_type":"code","source":"y_flat = np.ravel(y)\n\ny_series = pd.Series(y_flat)\n\nprint(\"Distribuzione delle classi (prima):\")\nprint(y_series.value_counts())\n\nclassi_da_mantenere = [cls for cls, cnt in counts.items() if cnt > 1]\n\nmask = np.array([label in classi_da_mantenere for label in y])\n\nX_filtrato = X[mask]\ny_filtrato = y[mask]\n\nprint(\"Classi ntenute:\", classi_da_mantenere)\nprint(\"Distribuzione dopo filtaggio:\", Counter(y_filtrato))\nX_train, X_test, y_train, y_test = train_test_split(X_filtrato, y_filtrato, test_size=0.2, random_state=42)\n\nparam_grid = {\n    'max_depth': [3, 4, 5, 6, 7, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['entropy']\n}\n\ndt = DecisionTreeClassifier()\ngrid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Migliori parametri trovati:\", grid_search.best_params_)\nprint(\"Miglior accuracy (train):\", grid_search.best_score_)\n\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\ntest_acc = accuracy_score(y_test, y_pred)\n\nprint(\"Accuracy sul test set:\", test_acc)","metadata":{},"outputs":[],"execution_count":null}]}